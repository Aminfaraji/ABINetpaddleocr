{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19HdTACqDamLqKzQAkITJMIAOM7JhmqTR",
      "authorship_tag": "ABX9TyN/76fT5APGWlv103F8usoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aminfaraji/ABINetpaddleocr/blob/main/salhe_job.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "btwIh9KTE5ji"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "!pip install torchmetrics\n",
        "!sudo apt-get install tesseract-ocr-fas\n",
        "!pip install pytesseract\n",
        "from torchmetrics.text import CharErrorRate ,WordErrorRate\n",
        "import pytesseract\n",
        "from glob import glob\n",
        "import shutil,os,cv2\n",
        "from difflib import SequenceMatcher\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "!pip install easyocr\n",
        "import easyocr\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # from IPython.display import Image\n",
        "# from PIL import Image\n",
        "# import requests\n",
        "\n",
        "# def show_image(image_name):\n",
        "#   return Image(filename=image_name)\n",
        "# reader_en_fr = easyocr.Reader(['en', 'fa'])\n",
        "\n",
        "# def read_text(image_name, model_name, in_line=False):\n",
        "\n",
        "#   # Read the data\n",
        "#   image_name = Image.open(image_name)\n",
        "#   text = model_name.readtext(image_name, detail = 0, paragraph=in_line)\n",
        "\n",
        "#   return '\\n'.join(text)"
      ],
      "metadata": {
        "id": "Uc6AdEgotSZU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # show_image(\"/content/drive/MyDrive/images/001A10.jpg\")\n",
        "# fr_text = read_text(\"/content/drive/MyDrive/images/001A10.jpg\", reader_en_fr)\n",
        "# print(fr_text)"
      ],
      "metadata": {
        "id": "FhkNZN7dtYQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def extract_texts_with_bndbox(element):\n",
        "    results = []\n",
        "    for obj in element.findall('.//object'):\n",
        "        content_element = obj.find('content')\n",
        "        bndbox_element = obj.find('bndbox')\n",
        "        if content_element is not None and bndbox_element is not None:\n",
        "            text = content_element.text.strip()\n",
        "            bndbox = {\n",
        "                'xmin': int(bndbox_element.find('xmin').text),\n",
        "                'ymin': int(bndbox_element.find('ymin').text),\n",
        "                'xmax': int(bndbox_element.find('xmax').text),\n",
        "                'ymax': int(bndbox_element.find('ymax').text),\n",
        "            }\n",
        "            results.append((text, bndbox))\n",
        "    return results\n",
        "\n",
        "def crop_image(image_path, bndbox):\n",
        "  image = cv2.imread(image_path)\n",
        "  X = bndbox['xmin']\n",
        "  Y = bndbox['ymin']\n",
        "  W = bndbox['xmax']\n",
        "  H = bndbox['ymax']\n",
        "  cropped_image = image[Y:H, X:W]\n",
        "  return cropped_image\n",
        "\n",
        "def ocr_image_tesseract(image):\n",
        "    text = pytesseract.image_to_string(image, lang='eng+fa')\n",
        "    return text\n",
        "\n",
        "def ocr_image_easyocr(reader, image):\n",
        "  result = reader.readtext(image , paragraph=True)\n",
        "  text = ' '.join([res[1] for res in result])\n",
        "  return text\n",
        "\n",
        "def calculate_error_rates(ground_truth, ocr_text):\n",
        "    char_error_rate = cer(ocr_text , ground_truth)\n",
        "    word_error_rate = wer(ocr_text , ground_truth)\n",
        "    return char_error_rate, word_error_rate\n",
        "\n",
        "def process_xml_file(xml_path, image_path, reader):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    texts_with_bndbox = extract_texts_with_bndbox(root)\n",
        "\n",
        "    results = []\n",
        "    for text, bndbox in texts_with_bndbox:\n",
        "        cropped_image = crop_image(image_path, bndbox)\n",
        "\n",
        "        ocr_text_tesseract = ocr_image_tesseract(cropped_image)\n",
        "        ocr_text_easyocr = ocr_image_easyocr(reader, cropped_image)\n",
        "\n",
        "        char_error_rate_tesseract, word_error_rate_tesseract = calculate_error_rates(text, ocr_text_tesseract)\n",
        "        char_error_rate_easyocr, word_error_rate_easyocr = calculate_error_rates(text, ocr_text_easyocr)\n",
        "\n",
        "        results.append({\n",
        "            'Original Text': text,\n",
        "            'OCR Text Tesseract': ocr_text_tesseract,\n",
        "            'OCR Text EasyOCR': ocr_text_easyocr,\n",
        "            'Bounding Box': f\"{bndbox['xmin']},{bndbox['ymin']},{bndbox['xmax']},{bndbox['ymax']}\",\n",
        "            'Character Error Rate Tesseract': char_error_rate_tesseract.item(),\n",
        "            'Word Error Rate Tesseract': word_error_rate_tesseract.item(),\n",
        "            'Character Error Rate EasyOCR': char_error_rate_easyocr.item(),\n",
        "            'Word Error Rate EasyOCR': word_error_rate_easyocr.item(),\n",
        "            'Image Path': os.path.basename(image_path),\n",
        "            'XML File': os.path.basename(xml_path)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "xml_files =glob('/content/drive/MyDrive/ArnaDataset/*.xml')\n",
        "image_files = '/content/drive/MyDrive/images/'\n",
        "all_data = []\n",
        "reader = easyocr.Reader(['en' , 'fa'])\n",
        "\n",
        "\n",
        "cer = CharErrorRate()\n",
        "wer = WordErrorRate()\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "\n",
        "    futures = []\n",
        "    with tqdm(total=len(xml_files)) as pbar:\n",
        "      for xml in xml_files:\n",
        "          futures.append(executor.submit(process_xml_file, xml, image_files+os.path.split(xml)[1][:-4]+'.jpg' , reader))\n",
        "\n",
        "      for future in as_completed(futures):\n",
        "          all_data.extend(future.result())\n",
        "          pbar.update(1)\n",
        "\n",
        "# for xml in tqdm(xml_files):\n",
        "#   all_data.extend(process_xml_file(xml,image_files+os.path.split(xml)[1][:-4]+'.jpg' , reader))\n",
        "\n",
        "df = pd.DataFrame(all_data)\n",
        "df.to_excel('output.xlsx', index=False)\n",
        "\n",
        "print(\"Data has been saved to output.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNQg_pJrlLOn",
        "outputId": "b75b00b7-94d5-4ecc-9816-c2d98a5caa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1001 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "  1%|          | 7/1001 [01:44<3:27:26, 12.52s/it]/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric WordErrorRate was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
            "  1%|          | 10/1001 [02:25<3:30:16, 12.73s/it]/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric WordErrorRate was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
            "  3%|▎         | 26/1001 [05:56<2:44:10, 10.10s/it]/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric CharErrorRate was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame(all_data)\n",
        "# df"
      ],
      "metadata": {
        "id": "i2SqWVeulJml"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bndbox = {'xmin' : 725 , 'ymin':124 , 'xmax':1116 , 'ymax' : 176}\n",
        "cropped_image = crop_image(image_files+'/011C9.jpg', bndbox)\n",
        "def ocr_image_easyocr(reader, image):\n",
        "  # image = cv2.imread(image)\n",
        "  result = reader.readtext(image , paragraph=True)\n",
        "  text = ' '.join([res[1] for res in result])\n",
        "  return text"
      ],
      "metadata": {
        "id": "zlY3xGJzx_DY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropped_image"
      ],
      "metadata": {
        "id": "MFP1geptrEL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ocr_image_easyocr(reader ,cropped_image)"
      ],
      "metadata": {
        "id": "v8YlzhTtnVx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bndbox = {'xmin' : 725 , 'ymin':124 , 'xmax':1116 , 'ymax' : 176}\n",
        "\n",
        "def crop_image(image_path, bndbox):\n",
        "  image = cv2.imread(image_path)\n",
        "  X = bndbox['xmin']\n",
        "  Y = bndbox['ymin']\n",
        "  W = bndbox['xmax']\n",
        "  H = bndbox['ymax']\n",
        "  cropped_image = image[Y:H, X:W]\n",
        "  return cropped_image"
      ],
      "metadata": {
        "id": "LhYYjaTn10xv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropped_image = crop_image(image_files+'/011C9.jpg', bndbox)\n",
        "ocr_image_easyocr(reader , cropped_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pPLQBxBJugxz",
        "outputId": "74bf4f87-fabb-494c-928c-2ef07f286645"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'شرکت های زیر مجموعه'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGm1AYyfusSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}